## **2. Configura√ß√£o do Ambiente Local**

Esta se√ß√£o guiar√° voc√™ atrav√©s da configura√ß√£o completa do ambiente local necess√°rio para executar o chatbot com LLaMA AI no WhatsApp. Vamos cobrir a instala√ß√£o de depend√™ncias, configura√ß√£o do modelo LLaMA, setup da API do WhatsApp e testes do ambiente.

### **2.1. Prepara√ß√£o do Ambiente**

Antes de come√ßar, certifique-se de que seu sistema est√° atualizado e pronto para as instala√ß√µes:

```bash
sudo apt update && sudo apt upgrade -y
```

### **2.2. Instala√ß√£o das Depend√™ncias Necess√°rias**

Certifique-se de instalar as ferramentas b√°sicas.

#### **Python e Pip**
Python ser√° necess√°rio para executar o modelo LLaMA e scripts do chatbot.

1. **Instale o Python:**
   ```bash
   sudo apt install python3 python3-pip python3-venv -y
   ```

2. **Verifique a vers√£o instalada:**
   ```bash
   python3 --version
   ```

3. **Atualize o Pip:**
   ```bash
   python3 -m pip install --upgrade pip
   ```

4. **Instale bibliotecas essenciais:**
   ```bash
   pip3 install torch torchvision torchaudio transformers accelerate
   pip3 install flask fastapi uvicorn requests qrcode[pil]
   ```

#### **Node.js e npm**
Necess√°rio para integra√ß√£o com APIs do WhatsApp.

1. **Instale o Node.js:**
   ```bash
   curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
   sudo apt install nodejs -y
   ```

2. **Verifique a instala√ß√£o:**
   ```bash
   node --version
   npm --version
   ```

3. **Instale depend√™ncias globais √∫teis:**
   ```bash
   npm install -g pm2 nodemon
   ```

### **2.3. Configura√ß√£o do Modelo LLaMA**

O modelo LLaMA ser√° o c√©rebro do seu chatbot. Vamos configur√°-lo usando a biblioteca Transformers da Hugging Face.

#### **Op√ß√£o 1: Modelo LLaMA via Hugging Face (Recomendado)**

1. **Instale as depend√™ncias espec√≠ficas:**
   ```bash
   pip3 install transformers[torch] accelerate bitsandbytes
   ```

2. **Crie um script de teste do modelo:**
   ```bash
   mkdir -p ~/chatbot-whatsapp/src
   cd ~/chatbot-whatsapp
   ```

   Crie o arquivo `test_llama.py`:
   ```python
   from transformers import AutoTokenizer, AutoModelForCausalLM
   import torch

   def test_llama_model():
       model_name = "microsoft/DialoGPT-medium"  # Modelo alternativo para teste
       # Para LLaMA oficial: "meta-llama/Llama-2-7b-chat-hf"
       
       print("Carregando modelo...")
       tokenizer = AutoTokenizer.from_pretrained(model_name)
       model = AutoModelForCausalLM.from_pretrained(
           model_name,
           torch_dtype=torch.float16,
           device_map="auto",
           low_cpu_mem_usage=True
       )
       
       # Teste b√°sico
       input_text = "Ol√°! Como posso ajudar voc√™ hoje?"
       inputs = tokenizer.encode(input_text, return_tensors="pt")
       
       with torch.no_grad():
           outputs = model.generate(
               inputs,
               max_length=100,
               num_return_sequences=1,
               temperature=0.7,
               do_sample=True,
               pad_token_id=tokenizer.eos_token_id
           )
       
       response = tokenizer.decode(outputs[0], skip_special_tokens=True)
       print(f"Resposta do modelo: {response}")
       return True

   if __name__ == "__main__":
       test_llama_model()
   ```

3. **Execute o teste:**
   ```bash
   python3 test_llama.py
   ```

#### **Op√ß√£o 2: LLaMA Oficial da Meta**

1. **Solicite acesso ao modelo oficial:**
   - Acesse: https://ai.meta.com/resources/models-and-libraries/llama-downloads/
   - Preencha o formul√°rio de solicita√ß√£o de acesso

2. **Ap√≥s aprova√ß√£o, baixe e configure:**
   ```bash
   # Instale a biblioteca oficial
   pip3 install llama-cpp-python
   
   # Crie diret√≥rio para modelos
   mkdir -p ~/models/llama
   
   # Ap√≥s baixar os modelos, extraia aqui:
   # cp /caminho/dos/modelos/baixados/* ~/models/llama/
   ```

3. **Configure permiss√µes:**
   ```bash
   chmod -R 755 ~/models/llama
   ```

### **2.4. Configura√ß√£o da API do WhatsApp**

Voc√™ pode escolher entre duas abordagens para integrar com o WhatsApp. Analisaremos os pr√≥s e contras de cada uma:

#### **Compara√ß√£o das APIs**

| Aspecto | API Oficial (WhatsApp Business) | API N√£o-Oficial (Baileys) |
|---------|----------------------------------|----------------------------|
| **Estabilidade** | ‚úÖ Alta | ‚ö†Ô∏è Vari√°vel |
| **Custo** | üí∞ Pago (ap√≥s limite gratuito) | üÜì Gratuito |
| **Configura√ß√£o** | üîß Complexa | ‚ö° Simples |
| **Risco de Bloqueio** | ‚ùå Nenhum | ‚ö†Ô∏è Existe |
| **Suporte** | ‚úÖ Oficial | üîß Comunidade |

#### **Op√ß√£o A: API Oficial do WhatsApp Business**

**Vantagens:**
- Suporte oficial e estabilidade garantida
- Melhor compatibilidade com futuras atualiza√ß√µes
- Maior controle sobre autentica√ß√£o e seguran√ßa

**Configura√ß√£o:**

1. **Crie uma conta de desenvolvedor Meta:**
   - Acesse: https://developers.facebook.com/
   - Registre um aplicativo WhatsApp Business

2. **Configure as credenciais:**
   ```bash
   # Crie arquivo de configura√ß√£o
   mkdir -p ~/chatbot-whatsapp/config
   ```

   Crie o arquivo `~/chatbot-whatsapp/config/whatsapp_config.json`:
   ```json
   {
     "whatsapp_token": "SEU_ACCESS_TOKEN_AQUI",
     "phone_number_id": "SEU_PHONE_NUMBER_ID_AQUI",
     "webhook_verify_token": "SEU_WEBHOOK_TOKEN_AQUI",
     "api_version": "v18.0"
   }
   ```

3. **Teste a conex√£o:**
   ```bash
   curl -X POST "https://graph.facebook.com/v18.0/PHONE_NUMBER_ID/messages" \
   -H "Authorization: Bearer ACCESS_TOKEN" \
   -H "Content-Type: application/json" \
   -d '{
     "messaging_product": "whatsapp",
     "to": "NUMERO_TESTE",
     "type": "text",
     "text": {"body": "Teste de conex√£o da API oficial!"}
   }'
   ```

#### **Op√ß√£o B: API N√£o-Oficial (Baileys)**

**Vantagens:**
- Configura√ß√£o r√°pida e simples
- Gratuita e sem burocracia
- Ideal para testes e projetos pequenos

**Configura√ß√£o:**

1. **Instale o Baileys:**
   ```bash
   cd ~/chatbot-whatsapp
   npm init -y
   npm install @whiskeysockets/baileys qrcode-terminal
   ```

2. **Crie script de conex√£o:**
   
   Arquivo `whatsapp_baileys.js`:
   ```javascript
   const { default: makeWASocket, DisconnectReason, useMultiFileAuthState } = require('@whiskeysockets/baileys');
   const qrcode = require('qrcode-terminal');

   async function connectWhatsApp() {
       const { state, saveCreds } = await useMultiFileAuthState('auth_info_baileys');
       
       const sock = makeWASocket({
           auth: state,
           printQRInTerminal: true
       });

       sock.ev.on('connection.update', (update) => {
           const { connection, lastDisconnect, qr } = update;
           
           if (qr) {
               console.log('QR Code gerado! Escaneie com seu WhatsApp:');
           }
           
           if (connection === 'close') {
               const shouldReconnect = (lastDisconnect.error)?.output?.statusCode !== DisconnectReason.loggedOut;
               console.log('Conex√£o fechada devido a ', lastDisconnect.error, ', reconectando ', shouldReconnect);
               if (shouldReconnect) {
                   connectWhatsApp();
               }
           } else if (connection === 'open') {
               console.log('Conectado ao WhatsApp com sucesso!');
           }
       });

       sock.ev.on('creds.update', saveCreds);

       // Teste de envio de mensagem
       sock.sendMessage = async (jid, message) => {
           try {
               await sock.sendMessage(jid, message);
               console.log('Mensagem enviada com sucesso!');
           } catch (error) {
               console.error('Erro ao enviar mensagem:', error);
           }
       };

       return sock;
   }

   module.exports = { connectWhatsApp };

   // Para testar diretamente
   if (require.main === module) {
       connectWhatsApp();
   }
   ```

3. **Execute o teste:**
   ```bash
   node whatsapp_baileys.js
   ```

   Escaneie o QR Code que aparecer√° no terminal com seu WhatsApp.

### **2.5. Configura√ß√£o Opcional com Docker**

Para um ambiente mais isolado e reproduz√≠vel, voc√™ pode usar Docker:

1. **Instale o Docker:**
   ```bash
   sudo apt install docker.io docker-compose -y
   sudo systemctl enable --now docker
   sudo usermod -aG docker $USER
   ```

2. **Crie um Dockerfile:**
   
   Arquivo `~/chatbot-whatsapp/Dockerfile`:
   ```dockerfile
   FROM python:3.9-slim

   WORKDIR /app

   # Instalar depend√™ncias do sistema
   RUN apt-get update && apt-get install -y \
       curl \
       wget \
       git \
       && rm -rf /var/lib/apt/lists/*

   # Instalar Node.js
   RUN curl -fsSL https://deb.nodesource.com/setup_18.x | bash - \
       && apt-get install -y nodejs

   # Copiar arquivos de requisitos
   COPY requirements.txt package.json ./

   # Instalar depend√™ncias Python e Node.js
   RUN pip install --no-cache-dir -r requirements.txt
   RUN npm install

   # Copiar c√≥digo da aplica√ß√£o
   COPY . .

   # Expor porta
   EXPOSE 5000

   # Comando para iniciar a aplica√ß√£o
   CMD ["python", "app.py"]
   ```

3. **Crie docker-compose.yml:**
   ```yaml
   version: '3.8'
   services:
     chatbot:
       build: .
       ports:
         - "5000:5000"
       volumes:
         - ./models:/app/models
         - ./config:/app/config
         - ./logs:/app/logs
       environment:
         - PYTHONUNBUFFERED=1
       restart: unless-stopped
   ```

### **2.6. Teste Completo do Ambiente**

Agora vamos validar se tudo est√° funcionando corretamente:

1. **Teste das depend√™ncias b√°sicas:**
   ```bash
   # Teste Python
   python3 --version

   # Teste Node.js
   node --version
   npm --version

   # Teste bibliotecas Python
   python3 -c "import torch; print('PyTorch:', torch.__version__)"
   python3 -c "import transformers; print('Transformers:', transformers.__version__)"

   # Teste Docker (se instalado)
   docker --version
   docker run hello-world
   ```

2. **Teste do modelo LLaMA:**
   ```bash
   cd ~/chatbot-whatsapp
   python3 test_llama.py
   ```

3. **Teste da conex√£o WhatsApp:**
   ```bash
   # Para Baileys
   node whatsapp_baileys.js

   # Para API oficial (substitua as credenciais)
   curl -X POST "https://graph.facebook.com/v18.0/PHONE_NUMBER_ID/messages" \
   -H "Authorization: Bearer ACCESS_TOKEN" \
   -H "Content-Type: application/json" \
   -d '{"messaging_product": "whatsapp", "to": "SEU_NUMERO", "type": "text", "text": {"body": "Teste da API oficial!"}}'
   ```

4. **Crie arquivo de requisitos Python:**
   
   Arquivo `~/chatbot-whatsapp/requirements.txt`:
   ```txt
   torch>=2.0.0
   transformers>=4.30.0
   accelerate>=0.20.0
   bitsandbytes>=0.39.0
   flask>=2.3.0
   fastapi>=0.100.0
   uvicorn>=0.22.0
   requests>=2.31.0
   python-dotenv>=1.0.0
   qrcode[pil]>=7.4.0
   ```

5. **Instale todas as depend√™ncias:**
   ```bash
   cd ~/chatbot-whatsapp
   pip3 install -r requirements.txt
   ```

### **2.7. Estrutura de Projeto Recomendada**

Organize seu projeto com a seguinte estrutura:

```
chatbot-whatsapp/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ llama_handler.py      # L√≥gica do modelo LLaMA
‚îÇ   ‚îú‚îÄ‚îÄ whatsapp_handler.py   # Integra√ß√£o WhatsApp
‚îÇ   ‚îî‚îÄ‚îÄ chatbot_logic.py      # L√≥gica principal do bot
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ whatsapp_config.json  # Configura√ß√µes WhatsApp
‚îÇ   ‚îî‚îÄ‚îÄ llama_config.json     # Configura√ß√µes do modelo
‚îú‚îÄ‚îÄ models/                   # Modelos baixados
‚îú‚îÄ‚îÄ logs/                     # Arquivos de log
‚îú‚îÄ‚îÄ auth_info_baileys/        # Autentica√ß√£o Baileys (se usar)
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ test_llama.py
‚îú‚îÄ‚îÄ whatsapp_baileys.js
‚îî‚îÄ‚îÄ app.py                    # Aplica√ß√£o principal
```

**‚úÖ Parab√©ns!** Seu ambiente local est√° configurado e pronto para a pr√≥xima etapa: integra√ß√£o do LLaMA com o WhatsApp.

---

**‚ö†Ô∏è Importante:** Guarde suas credenciais e tokens em local seguro. Nunca commite esses dados em reposit√≥rios p√∫blicos!
