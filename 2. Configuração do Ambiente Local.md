## **2. ConfiguraÃ§Ã£o do Ambiente Local**

Esta seÃ§Ã£o guiarÃ¡ vocÃª atravÃ©s da configuraÃ§Ã£o completa do ambiente local necessÃ¡rio para executar o chatbot com LLaMA AI no WhatsApp. Vamos cobrir a instalaÃ§Ã£o de dependÃªncias, configuraÃ§Ã£o do modelo LLaMA, setup da API do WhatsApp e testes do ambiente.

### **2.1. PreparaÃ§Ã£o do Ambiente**

Antes de comeÃ§ar, certifique-se de que seu sistema estÃ¡ atualizado e pronto para as instalaÃ§Ãµes:

```bash
sudo apt update && sudo apt upgrade -y
```

### **2.2. InstalaÃ§Ã£o das DependÃªncias NecessÃ¡rias**

Certifique-se de instalar as ferramentas bÃ¡sicas.

#### **Python e Pip**
Python serÃ¡ necessÃ¡rio para executar o modelo LLaMA e scripts do chatbot.

1. **Instale o Python:**
   ```bash
   sudo apt install python3 python3-pip python3-venv -y
   ```

2. **Verifique a versÃ£o instalada:**
   ```bash
   python3 --version
   ```

3. **Atualize o Pip:**
   ```bash
   python3 -m pip install --upgrade pip
   ```

4. **Instale bibliotecas essenciais:**
   ```bash
   pip3 install torch torchvision torchaudio transformers accelerate
   pip3 install flask fastapi uvicorn requests qrcode[pil]
   ```

#### **Node.js e npm**
NecessÃ¡rio para integraÃ§Ã£o com APIs do WhatsApp.

1. **Instale o Node.js:**
   ```bash
   curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
   sudo apt install nodejs -y
   ```

2. **Verifique a instalaÃ§Ã£o:**
   ```bash
   node --version
   npm --version
   ```

3. **Instale dependÃªncias globais Ãºteis:**
   ```bash
   npm install -g pm2 nodemon
   ```

### **2.3. ConfiguraÃ§Ã£o do Modelo LLaMA**

O modelo LLaMA serÃ¡ o cÃ©rebro do seu chatbot. Vamos configurÃ¡-lo usando a biblioteca Transformers da Hugging Face.

#### **OpÃ§Ã£o 1: Modelo LLaMA via Hugging Face (Recomendado)**

1. **Instale as dependÃªncias especÃ­ficas:**
   ```bash
   pip3 install transformers[torch] accelerate bitsandbytes
   ```

2. **Crie um script de teste do modelo:**
   ```bash
   mkdir -p ~/chatbot-whatsapp/src
   cd ~/chatbot-whatsapp
   ```

   Crie o arquivo `test_llama.py`:
   ```python
   from transformers import AutoTokenizer, AutoModelForCausalLM
   import torch

   def test_llama_model():
       model_name = "microsoft/DialoGPT-medium"  # Modelo alternativo para teste
       # Para LLaMA oficial: "meta-llama/Llama-2-7b-chat-hf"
       
       print("Carregando modelo...")
       tokenizer = AutoTokenizer.from_pretrained(model_name)
       model = AutoModelForCausalLM.from_pretrained(
           model_name,
           torch_dtype=torch.float16,
           device_map="auto",
           low_cpu_mem_usage=True
       )
       
       # Teste bÃ¡sico
       input_text = "OlÃ¡! Como posso ajudar vocÃª hoje?"
       inputs = tokenizer.encode(input_text, return_tensors="pt")
       
       with torch.no_grad():
           outputs = model.generate(
               inputs,
               max_length=100,
               num_return_sequences=1,
               temperature=0.7,
               do_sample=True,
               pad_token_id=tokenizer.eos_token_id
           )
       
       response = tokenizer.decode(outputs[0], skip_special_tokens=True)
       print(f"Resposta do modelo: {response}")
       return True

   if __name__ == "__main__":
       test_llama_model()
   ```

3. **Execute o teste:**
   ```bash
   python3 test_llama.py
   ```

#### **OpÃ§Ã£o 2: LLaMA Oficial da Meta**

1. **Solicite acesso ao modelo oficial:**
   - Acesse: https://ai.meta.com/resources/models-and-libraries/llama-downloads/
   - Preencha o formulÃ¡rio de solicitaÃ§Ã£o de acesso

2. **ApÃ³s aprovaÃ§Ã£o, baixe e configure:**
   ```bash
   # Instale a biblioteca oficial
   pip3 install llama-cpp-python
   
   # Crie diretÃ³rio para modelos
   mkdir -p ~/models/llama
   
   # ApÃ³s baixar os modelos, extraia aqui:
   # cp /caminho/dos/modelos/baixados/* ~/models/llama/
   ```

3. **Configure permissÃµes:**
   ```bash
   chmod -R 755 ~/models/llama
   ```

### **2.4. ConfiguraÃ§Ã£o da API do WhatsApp**

VocÃª pode escolher entre duas abordagens para integrar com o WhatsApp. Analisaremos os prÃ³s e contras de cada uma:

#### **ComparaÃ§Ã£o das APIs**

| Aspecto | API Oficial (WhatsApp Business) | API NÃ£o-Oficial (Baileys) |
|---------|----------------------------------|----------------------------|
| **Estabilidade** | âœ… Alta | âš ï¸ VariÃ¡vel |
| **Custo** | ğŸ’° Pago (apÃ³s limite gratuito) | ğŸ†“ Gratuito |
| **ConfiguraÃ§Ã£o** | ğŸ”§ Complexa | âš¡ Simples |
| **Risco de Bloqueio** | âŒ Nenhum | âš ï¸ Existe |
| **Suporte** | âœ… Oficial | ğŸ”§ Comunidade |

#### **OpÃ§Ã£o A: API Oficial do WhatsApp Business**

**Vantagens:**
- Suporte oficial e estabilidade garantida
- Melhor compatibilidade com futuras atualizaÃ§Ãµes
- Maior controle sobre autenticaÃ§Ã£o e seguranÃ§a

**ConfiguraÃ§Ã£o:**

1. **Crie uma conta de desenvolvedor Meta:**
   - Acesse: https://developers.facebook.com/
   - Registre um aplicativo WhatsApp Business

2. **Configure as credenciais:**
   ```bash
   # Crie arquivo de configuraÃ§Ã£o
   mkdir -p ~/chatbot-whatsapp/config
   ```

   Crie o arquivo `~/chatbot-whatsapp/config/whatsapp_config.json`:
   ```json
   {
     "whatsapp_token": "SEU_ACCESS_TOKEN_AQUI",
     "phone_number_id": "SEU_PHONE_NUMBER_ID_AQUI",
     "webhook_verify_token": "SEU_WEBHOOK_TOKEN_AQUI",
     "api_version": "v18.0"
   }
   ```

3. **Teste a conexÃ£o:**
   ```bash
   curl -X POST "https://graph.facebook.com/v18.0/PHONE_NUMBER_ID/messages" \
   -H "Authorization: Bearer ACCESS_TOKEN" \
   -H "Content-Type: application/json" \
   -d '{
     "messaging_product": "whatsapp",
     "to": "NUMERO_TESTE",
     "type": "text",
     "text": {"body": "Teste de conexÃ£o da API oficial!"}
   }'
   ```

#### **OpÃ§Ã£o B: API NÃ£o-Oficial (Baileys)**

**Vantagens:**
- ConfiguraÃ§Ã£o rÃ¡pida e simples
- Gratuita e sem burocracia
- Ideal para testes e projetos pequenos

**ConfiguraÃ§Ã£o:**

1. **Instale o Baileys:**
   ```bash
   cd ~/chatbot-whatsapp
   npm init -y
   npm install @whiskeysockets/baileys qrcode-terminal
   ```

2. **Crie script de conexÃ£o:**
   
   Arquivo `whatsapp_baileys.js`:
   ```javascript
   const { default: makeWASocket, DisconnectReason, useMultiFileAuthState } = require('@whiskeysockets/baileys');
   const qrcode = require('qrcode-terminal');

   async function connectWhatsApp() {
       const { state, saveCreds } = await useMultiFileAuthState('auth_info_baileys');
       
       const sock = makeWASocket({
           auth: state,
           printQRInTerminal: true
       });

       sock.ev.on('connection.update', (update) => {
           const { connection, lastDisconnect, qr } = update;
           
           if (qr) {
               console.log('QR Code gerado! Escaneie com seu WhatsApp:');
           }
           
           if (connection === 'close') {
               const shouldReconnect = (lastDisconnect.error)?.output?.statusCode !== DisconnectReason.loggedOut;
               console.log('ConexÃ£o fechada devido a ', lastDisconnect.error, ', reconectando ', shouldReconnect);
               if (shouldReconnect) {
                   connectWhatsApp();
               }
           } else if (connection === 'open') {
               console.log('Conectado ao WhatsApp com sucesso!');
           }
       });

       sock.ev.on('creds.update', saveCreds);

       // Teste de envio de mensagem
       sock.sendMessage = async (jid, message) => {
           try {
               await sock.sendMessage(jid, message);
               console.log('Mensagem enviada com sucesso!');
           } catch (error) {
               console.error('Erro ao enviar mensagem:', error);
           }
       };

       return sock;
   }

   module.exports = { connectWhatsApp };

   // Para testar diretamente
   if (require.main === module) {
       connectWhatsApp();
   }
   ```

3. **Execute o teste:**
   ```bash
   node whatsapp_baileys.js
   ```

   Escaneie o QR Code que aparecerÃ¡ no terminal com seu WhatsApp.

### **2.5. ConfiguraÃ§Ã£o Opcional com Docker**

Para um ambiente mais isolado e reproduzÃ­vel, vocÃª pode usar Docker:

1. **Instale o Docker:**
   ```bash
   sudo apt install docker.io docker-compose -y
   sudo systemctl enable --now docker
   sudo usermod -aG docker $USER
   ```

2. **Crie um Dockerfile:**
   
   Arquivo `~/chatbot-whatsapp/Dockerfile`:
   ```dockerfile
   FROM python:3.9-slim

   WORKDIR /app

   # Instalar dependÃªncias do sistema
   RUN apt-get update && apt-get install -y \
       curl \
       wget \
       git \
       && rm -rf /var/lib/apt/lists/*

   # Instalar Node.js
   RUN curl -fsSL https://deb.nodesource.com/setup_18.x | bash - \
       && apt-get install -y nodejs

   # Copiar arquivos de requisitos
   COPY requirements.txt package.json ./

   # Instalar dependÃªncias Python e Node.js
   RUN pip install --no-cache-dir -r requirements.txt
   RUN npm install

   # Copiar cÃ³digo da aplicaÃ§Ã£o
   COPY . .

   # Expor porta
   EXPOSE 5000

   # Comando para iniciar a aplicaÃ§Ã£o
   CMD ["python", "app.py"]
   ```

3. **Crie docker-compose.yml:**
   ```yaml
   version: '3.8'
   services:
     chatbot:
       build: .
       ports:
         - "5000:5000"
       volumes:
         - ./models:/app/models
         - ./config:/app/config
         - ./logs:/app/logs
       environment:
         - PYTHONUNBUFFERED=1
       restart: unless-stopped
   ```

### **2.6. Teste Completo do Ambiente**

Agora vamos validar se tudo estÃ¡ funcionando corretamente:

1. **Teste das dependÃªncias bÃ¡sicas:**
   ```bash
   # Teste Python
   python3 --version

   # Teste Node.js
   node --version
   npm --version

   # Teste bibliotecas Python
   python3 -c "import torch; print('PyTorch:', torch.__version__)"
   python3 -c "import transformers; print('Transformers:', transformers.__version__)"

   # Teste Docker (se instalado)
   docker --version
   docker run hello-world
   ```

2. **Teste do modelo LLaMA:**
   ```bash
   cd ~/chatbot-whatsapp
   python3 test_llama.py
   ```

3. **Teste da conexÃ£o WhatsApp:**
   ```bash
   # Para Baileys
   node whatsapp_baileys.js

   # Para API oficial (substitua as credenciais)
   curl -X POST "https://graph.facebook.com/v18.0/PHONE_NUMBER_ID/messages" \
   -H "Authorization: Bearer ACCESS_TOKEN" \
   -H "Content-Type: application/json" \
   -d '{"messaging_product": "whatsapp", "to": "SEU_NUMERO", "type": "text", "text": {"body": "Teste da API oficial!"}}'
   ```

4. **Crie arquivo de requisitos Python:**
   
   Arquivo `~/chatbot-whatsapp/requirements.txt`:
   ```txt
   torch>=2.0.0
   transformers>=4.30.0
   accelerate>=0.20.0
   bitsandbytes>=0.39.0
   flask>=2.3.0
   fastapi>=0.100.0
   uvicorn>=0.22.0
   requests>=2.31.0
   python-dotenv>=1.0.0
   qrcode[pil]>=7.4.0
   ```

5. **Instale todas as dependÃªncias:**
   ```bash
   cd ~/chatbot-whatsapp
   pip3 install -r requirements.txt
   ```

### **2.7. Estrutura de Projeto Recomendada**

Organize seu projeto com a seguinte estrutura:

```
chatbot-whatsapp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ llama_handler.py      # LÃ³gica do modelo LLaMA
â”‚   â”œâ”€â”€ whatsapp_handler.py   # IntegraÃ§Ã£o WhatsApp
â”‚   â””â”€â”€ chatbot_logic.py      # LÃ³gica principal do bot
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ whatsapp_config.json  # ConfiguraÃ§Ãµes WhatsApp
â”‚   â””â”€â”€ llama_config.json     # ConfiguraÃ§Ãµes do modelo
â”œâ”€â”€ models/                   # Modelos baixados
â”œâ”€â”€ logs/                     # Arquivos de log
â”œâ”€â”€ auth_info_baileys/        # AutenticaÃ§Ã£o Baileys (se usar)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ package.json
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ test_llama.py
â”œâ”€â”€ whatsapp_baileys.js
â””â”€â”€ app.py                    # AplicaÃ§Ã£o principal
```

**âœ… ParabÃ©ns!** Seu ambiente local estÃ¡ configurado e pronto para a prÃ³xima etapa: integraÃ§Ã£o do LLaMA com o WhatsApp.

---

**âš ï¸ Importante:** Guarde suas credenciais e tokens em local seguro. Nunca commite esses dados em repositÃ³rios pÃºblicos!
